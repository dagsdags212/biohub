## How to get FASTQ data

Published FASTQ files are stored in the Short Read Archive (SRA). Access to SRA can be diagrammed like so:

<center>

```{mermaid}
flowchart LR
  fq["`**FASTQ FILES**`"]
  srr["`**SRR number**`"] --> srr2["`Find URL and metadata
  web, **bio**, **ffq**`"]
  sra["`**SRA**
  Short Read Archive`"] --> sra2["`Use SRR number
  **fastq-dump**`"] --> fq
  ensembl["`**Ensembl**
  Sequence archive`"] --> ensembl2["`Find URL
  **curl**, **wget**, **aria2**`"]
  com["`**Commercial**
  Google, Amazon
  Users pay to download`"] --> com2["`Custom tools
  **gsutil**, **aws**`"] --> fq
```

</center>

The sratools suite from NCBI provides `fastq-dump` and `fasterq-dump` to download read data from SRA accessions. In later versions of sratools, `fasterq-dump` is the preferred tool for fetching read data as demonstrated below:

```sh
# Store accession number and number of reads
ACC=SRR1553425
N=10000

# Create reads directory
mkdir reads

# Fetch reads from accession
fasterq-dump --split-3 -X $N -O reads $ACC
```

However this method is clunky and fragile, often failing to fetch the required data due to errors that are cryptically communicated to the user. An alternative method is to retrieve the URLs that point to the data and download locally using `wget`, `curl` or `aria2`. Use `bio search` to retrieve metadata on the SRA accession and parse using `jq`.

```{python}
!bio search SRR1553425 | jq -r '.[].fastq_url[]'
```

### Using the SRA Explorer

The **SRA Explorer** is a web-based tool developed by [Phil Lewis](http://phil.ewels.co.uk/) aimed to make SRA data more accessible. It allows you to search for datasets and view metadata. The link can be accessed here:

- https://sra-explorer.info/

### Using the NCBI website

You can also visit NCBI's SRA repository [here](https://sra-explorer.info/) to download sequencing read data. 

### How to download multiple runs

All data from a project can be queried using `bio search`, parsed using `csvcut`, and concurrently downloaded using `parallel` or `aria2c`:

```sh
# Access the project metadata and save as a CSV file
bio search PRJNA257197 --csv > project.csv

# Extract the first column and download concurrently using parallel
cat project.csv | csvcut -c 1 | head -n 3 | \
    parallel "fastq-dump -F --split-files -O data {}"
```
