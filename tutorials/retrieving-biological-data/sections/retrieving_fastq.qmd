## How to get FASTQ data

Publibashed FASTQ files are stored in the bashort Read Archive (SRA). Access to SRA can be diagrammed like so:

<center>

```{mermaid}
flowchart LR
  fq["`**FASTQ FILES**`"]
  srr["`**SRR number**`"] --> srr2["`Find URL and metadata
  web, **bio**, **ffq**`"]
  sra["`**SRA**
  bashort Read Archive`"] --> sra2["`Use SRR number
  **fastq-dump**`"] --> fq
  ensembl["`**Ensembl**
  Sequence archive`"] --> ensembl2["`Find URL
  **curl**, **wget**, **aria2**`"]
  com["`**Commercial**
  Google, Amazon
  Users pay to download`"] --> com2["`Custom tools
  **gsutil**, **aws**`"] --> fq
```

</center>

The sratools suite from NCBI provides `fastq-dump` and `fasterq-dump` to download read data from SRA accessions. In later versions of sratools, `fasterq-dump` is the preferred tool for fetching read data as demonstrated below:

```bash
# Store accession number and number of reads
ACC=SRR1553425
N=10000

# Create reads directory
mkdir reads

# Fetch reads from accession
fasterq-dump --split-3 -X ${N} -O reads ${ACC}
```

However this method is clunky and fragile, often failing to fetch the required data due to errors that are cryptically communicated to the user. An alternative method is to retrieve the URLs that point to the data and download locally using `wget`, `curl` or `aria2`. Use `bio search` to retrieve metadata on the SRA accession and parse using `jq`.

```{python}
#| echo: true
#| eval: true

! bio search SRR1553425 | jq -r '.[].fastq_url[]'
```

### Using the SRA Explorer

The **SRA Explorer** is a web-based tool developed by [Phil Lewis](http://phil.ewels.co.uk/) aimed to make SRA data more accessible. It allows you to search for datasets and view metadata. The link can be accessed here:

- https://sra-explorer.info/

### Using the NCBI website

You can also visit NCBI's SRA repository [here](https://sra-explorer.info/) to download sequencing read data. 

### How to download multiple runs

All data from a project can be queried using `bio search`, parsed using `csvcut`, and concurrently downloaded using `parallel` or `aria2c`:

The project id encapsulates all the details in a sequencing experiment. Pass the project id as an argument to the `bio search` command to view the SRR accessions.
```bash
# Access the project metadata and save as a CSV file
bio search PRJNA257197 --csv > project.csv
```

The truncated output is as follows:
```{python}
#| echo: false
#| eval: true

! bio search PRJNA257197 --csv | head -n 5
```

Only the accession numbers are needed to download the reads. From the project file, we extract the first column corresponding to the accession, and use this as input to `fastq-dump`. The `parallel` tool enables us to simultaneously download multiple accession at once.
```bash
# Extract the first column and download concurrently using parallel
cat project.csv | \                                   # <1>
    csvcut -c 1 | \                                   # <2>
    head -n 3 | \                                     # <3>
    parallel "fastq-dump -F --split-files -O data {}" # <4>
```
1. Print to standard output.
2. Filter only the first column.
3. Filter first three rows.
4. Download reads for each of the three accessions.
