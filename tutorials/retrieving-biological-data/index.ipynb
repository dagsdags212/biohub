{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Retrieving Biological Data\"\n",
        "author: \"Jan Emmanuel Samson\"\n",
        "date: \"July 23, 2024\"\n",
        "description: \"Tools for downloading genomic data using the command line.\"\n",
        "categories:\n",
        "  - CLI\n",
        "  - API\n",
        "image: assets/cover.jpg\n",
        "execute:\n",
        "  freeze: true  \n",
        "---"
      ],
      "id": "3b98374c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sources of biological data\n",
        "\n",
        "**What are databases?**\n",
        "\n",
        "**Databases** are organized collections of structured information retrieved from various sources such as experiments, sensors, telemetry data and publications, to name a few. Information within the database is physically stored in computer systems and a set of programs manage how data flows in and out of the database. A **server** actively listens for *requests* sent by other computers to access the data. Upon validation, the server retrieves the data from the database and sends the data (*response*) to the requesting computer (or **client**).\n",
        "\n",
        "**Biological databases**\n",
        "\n",
        "In biology, high-throughput experiments had led to the generation of data in the scale of petabytes. An organizational scheme is needed to easily retrieve the data used for the generation of actionable insights, which is the ultimate goal of any analysis. **Biological databases** contain data generated from experiments in the fields as genomics, proteomics, metabolomics, epigenetics, and many more. Each data point reflects a particular attribute of a biological entity such as the function of a gene, structure of a protein, expression of a transcript, localization of mutation, etc.\n",
        "\n",
        "**Why should I care?**\n",
        "\n",
        "Prior to any analysis, data pertinent to the research question must first be collected in a useable form. Retrieving data may be as simple a going to NCBI, searching for a particular accession or query, and clicking a button to download a file in a specific format (e.g., FASTA, GFF). However, this approach is not scalable when attempting to process largescale data. As such, bioinformaticians have developed infrastructure for streamlining the process of data collection, allowing researchers from all backgrounds to retrieve the information they require in a straighforward manner.\n",
        "\n",
        "The aim of this write-up is to introduce you to a few command-line-based tools for downloading biological data. \n",
        "\n",
        "## How to get genome data\n",
        "\n",
        "Data is distributed via various repositories. The most commonly used ones are:\n",
        "\n",
        "<center>\n",
        "\n",
        "```{mermaid}\n",
        "%%| fig-width: 100%\n",
        "flowchart LR\n",
        "  1A[\"`**NCBI**\n",
        "  Genbank/RefSeq`\"]\n",
        "  1B[\"`Use numbers\n",
        "  **bio, efetch**`\"]\n",
        "  \n",
        "  2A[\"`**Ensembl**\n",
        "  **UCSC**\n",
        "  **FlyBase, WormBase**\n",
        "  Releases`\"]\n",
        "  2B[\"`Use URL\n",
        "  **curl, wget, aria2**\n",
        "  **genomepy, refgenie**`\"]\n",
        "  \n",
        "  3A[\"`**NCBI Assemblies**\n",
        "  RefSeq genomes`\"]\n",
        "  3B[\"`Use accession\n",
        "  **datasets**`\"]\n",
        "  \n",
        "  4A[\"`**Independent\n",
        "  Data Tools**`\"]\n",
        "  4B[\"`**genomepy**\n",
        "  **refgenie**`\"]\n",
        "  \n",
        "  5[\"`**File Formats**\n",
        "  FASTA, GFF, GTF, BED`\"]\n",
        "  \n",
        "  1A --> 1B --> 5\n",
        "  2A --> 2B --> 5\n",
        "  3A --> 3B --> 5\n",
        "  4A --> 4B --> 5\n",
        "```\n",
        "\n",
        "</center>\n",
        "\n",
        "In addition, there are software packages such as `refgenie` and `genomepy` that can be used to download and manage reference genomes.\n",
        "\n",
        "### Search for metadata\n",
        "\n",
        "The `bio` package is a CLI-based tool used for bioinformatics exploration. It contains commands for downloading, manipulating, and transforming sequence data. If you have an NCBI-based accession number, you can use the `bio search` command to get information on it.\n",
        "\n",
        "```sh\n",
        "# Use a GenBank accession\n",
        "bio search AF086833      # <1>\n",
        "\n",
        "# Use an SRA accession\n",
        "bio search SRR1553425    # <2>\n",
        "\n",
        "# Use a RefSeq assembly ID\n",
        "bio search GCA_000005845 # <3>\n",
        "\n",
        "# Use a query string\n",
        "bio search ecoli         # <3>\n",
        "```\n",
        "\n",
        "1. Searches GenBank\n",
        "2. Searches SRA\n",
        "3. Searches NCBI Genome\n",
        "\n",
        "Running the `bio search` command will return a JSON-formatted string which contains the metadata for a particular record. Use the `--csv` flag to output the metadata in a comma-delimited format. Similarly, use the `--csv` if you want tab-delimited data. \n",
        "\n",
        "Running `bio search SRR1553425` would produce the following:"
      ],
      "id": "bed1831d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: true\n",
        "\n",
        "! micromamba run -n bioinfo bio search SRR1553425"
      ],
      "id": "502d5ce3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then use the `jq` processing tool to extract fields of interest. Extract the `fastq_url` list by running:"
      ],
      "id": "121a7867"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "! bio search SRR1553425 | jq \".[].fastq_url[]\""
      ],
      "id": "31f57c40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accessing Genbank\n",
        "\n",
        "GenBank is the NIH genetic sequence database, an annotated collection of publicly available DNA sequences. If your data has a GenBank accession number such as `AF086833`, use the `bio fetch` command. By default, data is printed to stdout. Override this behavior by specifying the output filename with the `-o` flag or redirect the output to a file with the `>` operator.\n",
        "\n",
        "```bash\n",
        "# Accession id pointing to the record.\n",
        "ACC=AF086833                                # <1>\n",
        "\n",
        "# Specify output with a flag.\n",
        "bio fetch ${ACC} --format fasta -o ${ACC}.fa # <2>\n",
        "\n",
        "# Redirect the output to a file.\n",
        "bio fetch ${ACC} --format gff > ${ACC}.gff  # <3>\n",
        "```\n",
        "1. Store accesssion ID as a variable.\n",
        "2. Download the sequence (FASTA) file.\n",
        "3. Download the annotation (GFF) file.\n",
        "\n",
        "Let us verify the download by viewing the first ten lines of the annotation file:"
      ],
      "id": "5132e720"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: true\n",
        "\n",
        "! bio fetch AF086833 --format gff | head -n 10"
      ],
      "id": "b270c446",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download via URL\n",
        "\n",
        "If you know the URL of a resource, you may use `wget` or `curl` to download the file. First, save the URL to a variable for referencing:\n",
        "```bash\n",
        "URL=http://ftp.ensembl.org/pub/release-104/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz\n",
        "```\n",
        "\n",
        "Use `curl`:\n",
        "```bash\n",
        "curl ${URL} -o chr22.fa.gz\n",
        "```\n",
        "  \n",
        "Or use `wget`:\n",
        "```bash\n",
        "wget -nc ${URL} -o chr22.fa.gz\n",
        "```\n",
        "\n",
        "The `-nc` flag would skip the download altogether if the file already exists. Use this flag to ensure that large files are not overwritten.\n",
        "\n",
        "For large files, [aria2](https://aria2.github.io/) can be used for faster, multi-segmented downloads. The tool also supports checkpoints which allow you to restart interrupted downloads. Download aria2 from their website or use `conda` to install in an environment.\n",
        "```bash\n",
        "aria2c ${URL} \\ \n",
        "  -x 5 \\           # <1>\n",
        "  -o chr22.fa.gz   # <2>\n",
        "```\n",
        "1. Connect to the server with x connections.\n",
        "2. Save the output to a file.\n",
        "\n",
        "\n",
        "### How to use NCBI datasets\n",
        "\n",
        "[NCBI Datasets](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/download-and-install/) is a new resource designed by NCBI to gather data from across NCBI databases. The main entry point of the tool is the `datasets` command. Subcommands such as `download` or `summary` is then specified, followed by more subcommands to specify your query.\n",
        "\n",
        "It seems to be the direction that NCBI wants to shepherd users towards. However, the nested structure of running the tool makes its use complicated and convoluted compared to other resources. NCBI is kind enough to give us a diagram for navigating the subcommands:\n",
        "\n",
        "<center>\n",
        "\n",
        "![](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/datasets_schema_taxonomy.svg)\n",
        "\n",
        "</center>\n",
        "\n",
        "Swiftwater hydra (*Hydra vulgaris*) has a taxonomy id of `6087` and RefSeq id of `GCF_038396675.1`. We can download its genome by running the following:\n",
        "```sh\n",
        "datasets download genome accession GCF_038396675.1\n",
        "```\n",
        "\n",
        "By default, genome is downloaded as a zipped file named **ncbi_dataset**. The structure of the directory is seen below.\n",
        "```\n",
        "ncbi_dataset\n",
        "└── data\n",
        "    ├── assembly_data_report.jsonl\n",
        "    ├── dataset_catalog.json\n",
        "    └── GCF_038396675.1\n",
        "        └── GCF_038396675.1_HydraT2T_AEP_genomic.fn\n",
        "```\n",
        "\n",
        "### How to access Ensembl\n",
        "\n",
        "Ensembl operates on numbered releases. For example, [release 104](http://ftp.ensembl.org/pub/release-104/) was published on March 30, 2021. Data can be retrieved by navigating the file tree in the provided FTP server. Alternatively, you can invoke `curl`, `wget`, or `aria2c` directly on each file.\n",
        "\n",
        "```sh\n",
        "# Get the FASTA file from chromosome 22 of the human genome\n",
        "URL=http://ftp.ensembl.org/pub/release-104/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz\n",
        "\n",
        "# Use curl go download the data\n",
        "curl ${URL} | gunzip -c > refs/chr22.fa # <1>\n",
        "```\n",
        "1. Download from URL and decompress the FASTA file.\n",
        "\n",
        "## How to use refgenie\n",
        "\n",
        "Refgenie is a command-line tool that can be used to download and manage reference genomes, and to build and manage custom genome assets. It also provides a Python interface for programmatic access to genome assets.\n",
        "\n",
        "<center>\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "  list[\"`**refgenie**\n",
        "  list`\"]\n",
        "  pull[\"`**refgenie**\n",
        "  pull`\"]\n",
        "  seek[\"`**refgenie**\n",
        "  seek`\"]\n",
        "  list --> pull --> seek\n",
        "```\n",
        "\n",
        "</center>\n",
        "\n",
        "### Installation\n",
        "\n",
        "Refgenie can be installed as a Python package using `pip`:\n",
        "\n",
        "```bash\n",
        "# Install using pip.\n",
        "pip install refgenie\n",
        "\n",
        "# Install using pipx.\n",
        "pipx install refgenie\n",
        "```\n",
        "\n",
        "or conda:\n",
        "\n",
        "```sh\n",
        "conda install -c conda-forge refgenie\n",
        "\n",
        "# Use mamba/micromamba instead of conda\n",
        "micromamba install refgenie\n",
        "```\n",
        "\n",
        "### Create a config file\n",
        "\n",
        "`refgenie` requires a configuration file that lists the resources in the form of a yaml file. For that you need to select a directory that will store the downloaded resources. The path to the config file is saved as the `REFGENIE` shell environment variable which will be used for initialization:\n",
        "\n",
        "```bash\n",
        "# Path pointing to refgenie config file.\n",
        "export REFGENIE=~/refs/config.yaml\n",
        "\n",
        "# Load the REFGENIE variable when launching a shell instance\n",
        "echo \"export REFGENIE=~/refs/config.yml\" >> ~/.bashrc\n",
        "source ~/.bashrc\n",
        "\n",
        "# Run initialization\n",
        "refgenie init\n",
        "```\n",
        "\n",
        "The `refgenie` tool is now ready to be used to download and manage reference genomes.\n",
        "\n",
        "### Using refgenie\n",
        "\n",
        "A list of pre-built assets from a remote server can be displayed with `listr`:"
      ],
      "id": "a3900cc4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "! refgenie listr"
      ],
      "id": "211ec257",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Genome data is fetched using the `pull` command:\n",
        "```bash\n",
        "refgenie pull hg38/bwa_index\n",
        "```\n",
        "\n",
        "The `seek` command displays the path of the downloaded file:\n",
        "```bash\n",
        "refgenie seek hg38/bwa_index\n",
        "```\n",
        "\n",
        "List local genome assets:\n",
        "```bash\n",
        "refgenie list\n",
        "```\n",
        "\n",
        "Use command substitution to store the genome path to a variable:\n",
        "```bash\n",
        "# Retrieve the human reference genome\n",
        "refgenie pull hg38/fasta\n",
        "\n",
        "# Save path of reference genome to a variable\n",
        "REF=$(refgenie seek hg38/fasta)\n",
        "```\n",
        "\n",
        "Then use the resulting path in downstream tools:\n",
        "```sh\n",
        "# Generate statistics for the human reference genome\n",
        "seqkit stats ${REF}\n",
        "```\n",
        "\n",
        "Subscribe to the iGenomes server which hosts additional reference genomes and genome assets.\n",
        "\n",
        "```sh\n",
        "refgenie subscribe -s http://igenomes.databio.org/\n",
        "```\n",
        "\n",
        "## Using genomepy\n",
        "\n",
        "### How to use genomepy\n",
        "\n",
        "`genomepy` is another tool designed for searching and downloading genomic data. It can be used to:\n",
        "\n",
        "1. search available data\n",
        "2. show the available metadata\n",
        "3. automatically download, preprocess\n",
        "4. generate optional aligned indexes\n",
        "\n",
        "Currently, `genomepy` supports Ensembl, UCSC, NCBI, and GENCODE.\n",
        "\n",
        "<center>\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "  genomepy[\"`**genomepy**`\"]\n",
        "  commands{\"`**search**\n",
        "  **install**\n",
        "  **annotation**`\"}\n",
        "  storage[\"`files stored in\n",
        "  **$home/local/share/genomes**`\"]\n",
        "  \n",
        "  genomepy --> commands --> storage\n",
        "```\n",
        "\n",
        "</center>\n",
        "\n",
        "See also: [genomepy documentation](https://github.com/vanheeringen-lab/genomepy)\n",
        "\n",
        "### Installation\n",
        "\n",
        "Install using micromamba:\n",
        "```bash\n",
        "micromamba install genomepy\n",
        "```\n",
        "\n",
        "Install using pip or pipx:\n",
        "```bash\n",
        "pipx install genomepy\n",
        "```\n",
        "\n",
        "### Using genomepy\n",
        "\n",
        "Use the `search` command to query genomes by name or accession:\n",
        "```bash\n",
        "genomepy search ecoli > ecoli_query_results.txt\n",
        "```\n",
        "\n",
        "A genome index will be downloaded upon invoking the `search` command for the first time. Hence, the initial search may take a while depending on your connection speed. As seen from the log below, assembly summaries are fetched from multiple databases (GENCODE, UCSC, Ensembl, NCBI).\n",
        "\n",
        "```md\n",
        "05:28:31 | INFO | Downloading assembly summaries from GENCODE\n",
        "05:29:54 | INFO | Downloading assembly summaries from UCSC\n",
        "05:30:05 | INFO | Downloading assembly summaries from Ensembl\n",
        "05:30:43 | INFO | Downloading assembly summaries from NCBI, this will take a while...\n",
        "genbank_historical: 73.0k genomes [00:06, 11.1k genomes/s]\n",
        "refseq_historical: 85.6k genomes [00:05, 16.6k genomes/s]\n",
        "genbank: 2.39M genomes [02:11, 18.1k genomes/s]\n",
        "refseq: 378k genomes [00:28, 13.0k genomes/s] \n",
        "```\n",
        "\n",
        "The results look like so:\n",
        "```md\n",
        "name                 provider accession         tax_id annotation species                                  other_info                              \n",
        "                                                        n r e k   <- UCSC options (see help)                                                       \n",
        "EcoliT22_2.0         NCBI     GCF_000247665.3      562     ✓      Escherichia coli O157:H43 str. T22       BAYGEN                                  \n",
        "Ecoli.O104:H4.LB226692_2.0 NCBI     GCA_000215685.3      562     ✓      Escherichia coli O104:H4 str. LB226692   Life Technologies                       \n",
        "Ecoli.O104:H4.01-09591_1.0 NCBI     GCA_000221065.2      562     ✓      Escherichia coli O104:H4 str. 01-09591   Life Technologies                       \n",
        "Ecoli_C227-11_1.0    NCBI     GCA_000220805.2      562     ✓      Escherichia coli O104:H4 str. C227-11    PacBio                                  \n",
        "ecoli009             NCBI     GCA_900607665.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli006             NCBI     GCA_900607465.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli008             NCBI     GCA_900607535.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli017             NCBI     GCA_900608025.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli025             NCBI     GCA_900608175.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli022             NCBI     GCA_900608105.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli015             NCBI     GCA_900607975.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL         \n",
        "ecoli013             NCBI     GCA_900607805.1      562     ✓      Escherichia coli                         BIOZENTRUM, UNIVERSITY OF BASEL       \n",
        "```\n",
        "\n",
        "Entries under the `name` field can be used to download the genome:\n",
        "```bash\n",
        "genomepy install ecoli009\n",
        "```\n",
        "\n",
        "By default, the downloaded genomes will be found in the `~/.local/share/genomes` directory. For our example, the directory named `ecoli009` contains the genome data and other relevant files:"
      ],
      "id": "b10f9547"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: true\n",
        "\n",
        "! tree ~/.local/share/genomes"
      ],
      "id": "2ed9ec83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to get FASTQ data\n",
        "\n",
        "Publibashed FASTQ files are stored in the bashort Read Archive (SRA). Access to SRA can be diagrammed like so:\n",
        "\n",
        "<center>\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "  fq[\"`**FASTQ FILES**`\"]\n",
        "  srr[\"`**SRR number**`\"] --> srr2[\"`Find URL and metadata\n",
        "  web, **bio**, **ffq**`\"]\n",
        "  sra[\"`**SRA**\n",
        "  bashort Read Archive`\"] --> sra2[\"`Use SRR number\n",
        "  **fastq-dump**`\"] --> fq\n",
        "  ensembl[\"`**Ensembl**\n",
        "  Sequence archive`\"] --> ensembl2[\"`Find URL\n",
        "  **curl**, **wget**, **aria2**`\"]\n",
        "  com[\"`**Commercial**\n",
        "  Google, Amazon\n",
        "  Users pay to download`\"] --> com2[\"`Custom tools\n",
        "  **gsutil**, **aws**`\"] --> fq\n",
        "```\n",
        "\n",
        "</center>\n",
        "\n",
        "The sratools suite from NCBI provides `fastq-dump` and `fasterq-dump` to download read data from SRA accessions. In later versions of sratools, `fasterq-dump` is the preferred tool for fetching read data as demonstrated below:\n",
        "\n",
        "```bash\n",
        "# Store accession number and number of reads\n",
        "ACC=SRR1553425\n",
        "N=10000\n",
        "\n",
        "# Create reads directory\n",
        "mkdir reads\n",
        "\n",
        "# Fetch reads from accession\n",
        "fasterq-dump --split-3 -X ${N} -O reads ${ACC}\n",
        "```\n",
        "\n",
        "However this method is clunky and fragile, often failing to fetch the required data due to errors that are cryptically communicated to the user. An alternative method is to retrieve the URLs that point to the data and download locally using `wget`, `curl` or `aria2`. Use `bio search` to retrieve metadata on the SRA accession and parse using `jq`."
      ],
      "id": "6026389f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "! bio search SRR1553425 | jq -r '.[].fastq_url[]'"
      ],
      "id": "f6a6d56a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the SRA Explorer\n",
        "\n",
        "The **SRA Explorer** is a web-based tool developed by [Phil Lewis](http://phil.ewels.co.uk/) aimed to make SRA data more accessible. It allows you to search for datasets and view metadata. The link can be accessed here:\n",
        "\n",
        "- https://sra-explorer.info/\n",
        "\n",
        "### Using the NCBI website\n",
        "\n",
        "You can also visit NCBI's SRA repository [here](https://sra-explorer.info/) to download sequencing read data. \n",
        "\n",
        "### How to download multiple runs\n",
        "\n",
        "All data from a project can be queried using `bio search`, parsed using `csvcut`, and concurrently downloaded using `parallel` or `aria2c`:\n",
        "\n",
        "The project id encapsulates all the details in a sequencing experiment. Pass the project id as an argument to the `bio search` command to view the SRR accessions.\n",
        "```bash\n",
        "# Access the project metadata and save as a CSV file\n",
        "bio search PRJNA257197 --csv > project.csv\n",
        "```\n",
        "\n",
        "The truncated output is as follows:"
      ],
      "id": "6a40fb93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: true\n",
        "\n",
        "! bio search PRJNA257197 --csv | head -n 5"
      ],
      "id": "3011954e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only the accession numbers are needed to download the reads. From the project file, we extract the first column corresponding to the accession, and use this as input to `fastq-dump`. The `parallel` tool enables us to simultaneously download multiple accession at once.\n",
        "```bash\n",
        "# Extract the first column and download concurrently using parallel\n",
        "cat project.csv | \\                                   # <1>\n",
        "    csvcut -c 1 | \\                                   # <2>\n",
        "    head -n 3 | \\                                     # <3>\n",
        "    parallel \"fastq-dump -F --split-files -O data {}\" # <4>\n",
        "```\n",
        "1. Print to standard output.\n",
        "2. Filter only the first column.\n",
        "3. Filter first three rows.\n",
        "4. Download reads for each of the three accessions.\n"
      ],
      "id": "de252f09"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}